<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>SoundSwallower</title>
  </head>
  <body>
    <h2>SoundSwallower live demo</h2>
    <ul>
      <li>This demo works on recent versions of Chrome and Firefox with the Web Audio API, make sure it works for you and actually records audio.</li>
      <li>Press "Start" and speak</li>
    </ul>
    <select id="grammars"></select>
    <button id="startBtn">Start</button>
    <button id="stopBtn">Stop</button>
    <span id="recording-indicator" style="border-radius: 10px; -moz-border-radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; background: red;"></span>
    <h2>Recognition Output</h2>
    <div id="output" style="height:150px;overflow:auto;" >
    </div>
    <h2>Status</h2>
    <div id="current-status">Loading page</div>

    <script>
      // These will be initialized later
      var recognizer, recorder, callbackManager, outputContainer, audioContext;
      // Only when both recorder and recognizer do we have a ready application
      var isRecorderReady = isRecognizerReady = false;

      // A convenience function to post a message to the recognizer and associate
      // a callback to its response
      function postRecognizerJob(message, callback) {
          var msg = message || {};
          if (callbackManager) msg.callbackId = callbackManager.add(callback);
          if (recognizer) recognizer.postMessage(msg);
      };

      // This function initializes an instance of the recorder
      // it posts a message right away and calls onReady when it
      // is ready so that onmessage can be properly set
      function spawnWorker(workerURL, onReady) {
          recognizer = new Worker(workerURL);
          recognizer.onmessage = function(event) {
              onReady(recognizer);
          };
          // As arguments, you can pass non-default path to pocketsphinx.js and pocketsphinx.wasm:
          // recognizer.postMessage({'pocketsphinx.wasm': '/path/to/pocketsphinx.wasm', 'pocketsphinx.js': '/path/to/pocketsphinx.js'});
          recognizer.postMessage({});
      };

      // To display the hypothesis sent by the recognizer
      function updateHyp(hyp) {
          if (outputContainer) outputContainer.innerHTML = hyp;
      };

      // This updates the UI when the app might get ready
      function updateUI() {
          if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      // This is just a logging window where we display the status
      function updateStatus(newStatus) {
          document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      // A not-so-great recording indicator
      function displayRecording(display) {
          if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
          else document.getElementById('recording-indicator').innerHTML = "";
      };

      // Callback function once the user authorises access to the microphone
      // in it, we instanciate the recorder
      function startUserMedia(stream) {
          var input = audioContext.createMediaStreamSource(stream);
          // Firefox hack https://support.mozilla.org/en-US/questions/984179
          window.firefox_audio_hack = input; 
          var audioRecorderConfig = {errorCallback: function(x) {updateStatus("Error from recorder: " + x);}};
          recorder = new AudioRecorder(input, audioRecorderConfig);
          // If a recognizer is ready, we pass it to the recorder
          if (recognizer) recorder.consumers = [recognizer];
          isRecorderReady = true;
          updateUI();
          updateStatus("Audio recorder ready");
      };

      // This starts recording. We first need to get the grammar to use
      var startRecording = function() {
	  audioContext.resume()
          if (recorder && recorder.start()) displayRecording(true);
      };

      // Stops recording
      var stopRecording = function() {
          recorder && recorder.stop();
          displayRecording(false);
      };

      // Called once the recognizer is ready
      // We then add the grammars to the input select tag and update the UI
      var recognizerReady = function() {
          updateGrammars();
          isRecognizerReady = true;
          updateUI();
          updateStatus("Recognizer ready");
      };

      // We get the grammars defined below and fill in the input select tag
      var updateGrammars = function() {
          var selectTag = document.getElementById('grammars');
	  for (const name in grammars) {
              var newElt = document.createElement('option');
              newElt.innerHTML = name;
              selectTag.appendChild(newElt);
          }                          
	  selectTag.onchange = function() {
	      var name = this.options[this.selectedIndex].innerText;
	      postRecognizerJob({command: 'setGrammar', data: grammars[name]},
				function() {
				    updateStatus("Set grammar to " + name);
				});
	  }
	  // selectTag.onchange();
      };

      // This initializes the recognizer. When it calls back, we add words
      var initRecognizer = function() {
          // You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
          postRecognizerJob({command: 'initialize',
			     data: [["-hmm", "en-us"],
				    ["-fsg", "goforward.fsg"],
				    ["-dict","en-us.dict"]]},
			    recognizerReady);
      };

      // When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
      // request access to the microphone
      window.onload = function() {
          outputContainer = document.getElementById("output");
          updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");
          callbackManager = new CallbackManager();
          spawnWorker("js/recognizer.js", function(worker) {
              // This is the onmessage function, once the worker is fully loaded
              worker.onmessage = function(e) {
                  // This is the case when we have a callback id to be called
                  if (e.data.hasOwnProperty('id')) {
                      var clb = callbackManager.get(e.data['id']);
                      var data = {};
                      if ( e.data.hasOwnProperty('data')) data = e.data.data;
                      if(clb) clb(data);
                  }
                  // This is a case when the recognizer has a new hypothesis
                  if (e.data.hasOwnProperty('hyp')) {
                      var newHyp = e.data.hyp;
                      if (e.data.hasOwnProperty('final') &&  e.data.final) newHyp = "Final: " + newHyp;
                      updateHyp(newHyp);
                  }
                  // This is the case when we have an error
                  if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                      updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                  }
              };
              // Once the worker is fully loaded, we can call the initialize function
              postRecognizerJob({command: 'lazyLoad',
				 data: {folders: [["/", "en-us"]],
					files: [
                                            ["/", "en-us.dict", "../model/en-us.dict"],
                                            ["/", "goforward.fsg", "../goforward.fsg"],
					    ["/en-us", "feat.params", "../model/en-us/feat.params"],
					    ["/en-us", "mdef", "../model/en-us/mdef"],
					    ["/en-us", "means", "../model/en-us/means"],
					    ["/en-us", "noisedict", "../model/en-us/noisedict"],
					    ["/en-us", "sendump", "../model/en-us/sendump"],
					    ["/en-us", "transition_matrices", "../model/en-us/transition_matrices"],
					    ["/en-us", "variances", "../model/en-us/variances"]
					]}
				}, initRecognizer);
          });

	  try {
	      window.AudioContext = window.AudioContext || window.webkitAudioContext;
	      window.URL = window.URL || window.webkitURL;
	      audioContext = new AudioContext();
	  } catch (e) {
	      updateStatus("Error initializing Web Audio browser");
	  }
	  if (navigator.mediaDevices.getUserMedia) navigator.mediaDevices.getUserMedia({audio: true}).then(startUserMedia).catch(function(e) {
	      updateStatus("No live audio input in this browser");
	  });
	  else updateStatus("No web audio support in this browser");
	  // Wiring JavaScript to the UI
	  var startBtn = document.getElementById('startBtn');
	  var stopBtn = document.getElementById('stopBtn');
	  startBtn.disabled = true;
	  stopBtn.disabled = true;
	  startBtn.onclick = startRecording;
	  stopBtn.onclick = stopRecording;
      };

      // This grammar recognizes digits
      var grammarDigits = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "ONE"},{from: 0, to: 0, word: "TWO"},{from: 0, to: 0, word: "THREE"},{from: 0, to: 0, word: "FOUR"},{from: 0, to: 0, word: "FIVE"},{from: 0, to: 0, word: "SIX"},{from: 0, to: 0, word: "SEVEN"},{from: 0, to: 0, word: "EIGHT"},{from: 0, to: 0, word: "NINE"},{from: 0, to: 0, word: "ZERO"}]};
      // This grammar recognizes a few cities names
      var grammarCities = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "NEW-YORK"}, {from: 0, to: 0, word: "NEW-YORK-CITY"}, {from: 0, to: 0, word: "PARIS"}, {from: 0, to: 0, word: "SHANGHAI"}, {from: 0, to: 0, word: "SAN-FRANCISCO"}, {from: 0, to: 0, word: "LONDON"}, {from: 0, to: 0, word: "BERLIN"}]};
      var grammars = {"Digits": grammarDigits, "Cities": grammarCities};
						       </script>
    <!-- These are the two JavaScript files you must load in the HTML,
	 The recognizer is loaded through a Web Worker -->
    <script src="js/audioRecorder.js"></script>
    <script src="js/callbackManager.js"></script>
  </body>
</html>
